# Batch Normalization

A detailed lesson on batch normalization. The idea is to re-orient the output of each layer in a deep neural network to have a mean of 0 and a variance of 1. As neural networks learn best when its input is normalized so that it doesn't have to search away from the origin as much, so too can the deeper layers be viewed the same way. The result is a network that can typically learn _much_ quicker, as it can find minimums much more easily.
