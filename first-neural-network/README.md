# Your First Neural Network (Project 1)

Here I went through and implemented a two-layer neural network from scratch using Numpy. There was a lot of handholding for the complex parts, but what it really tested was my understanding of the fundamental concepts in deep learning: feedforward, loss, and backpropagation using gradient descent. As with most foreign concepts, the initial understanding took some effort, but after that point it was much easier to learn new concepts on top of that.

What really astonishes me is how such simple and approachable math can achieve such incredible results. It's pretty much calculus for the learning part, and linear algebra for the performance part mashed together to form a deadly weapon. Wielding it harnesses immense power; given that you have adequate labeled example data, you can stand back and watch as your network learns the necessary features to achieve the results you are after.

As a final note: the Udacity reviewer was quite excellent. They got back to me within a day, and wrote up a myriad of comments on performance and suggestions for improvement. I don't think I have ever received such prompt and detailed feedback in my CS undergraduate years. A+
